# ArabicLLM-NeuroScope
ğŸ¯ Multilingual LLM Evaluation Suite for Arabic NLP.

Analyze activation flow, token strength & semantic bias of prompts in Fusha, Dialect, and English.

## ğŸ§  Overview
ArabicLLM-NeuroScope is a lightweight, reproducible framework for analyzing the behavior of Large Language Models (LLMs) when processing prompts in:

ğŸ‡¬ğŸ‡§ English (reference baseline)
ğŸ‡¸ğŸ‡¦ Modern Standard Arabic (Fusha)
ğŸ—£ï¸ Spoken Arabic Dialects (e.g. Saudi dialect)

It visualizes token activations, layer norms, and prompt flow across transformer layers â€“ both neuronally and semantically.
```
## ğŸ“‚ Folder Structure
ArabicLLM-NeuroScope/
â”œâ”€â”€ prompt_analysis/           # Norm activation analysis
â”œâ”€â”€ nlp_analysis/              # Token-level NLP evaluation
â”œâ”€â”€ visual/                    # Plots (2D/3D PNG & HTML)
â”œâ”€â”€ data/                      # Prompt files & JSON outputs
â”œâ”€â”€ diagrams/                  # Mermaid diagrams & flowcharts
â””â”€â”€ README.md
```
## ğŸ” Prompt Activation Analysis
This analysis measures token firepower across layers using activation norms:
$\|h_i\| = \sqrt{h_1^2 + h_2^2 + ... + h_d^2}$

Higher norms across more layers = deeper processing. Lower activation = bias, poor embedding, or soft filters.

ğŸ§ª Tested prompts:

* English: "What is the history of artificial intelligence in the Middle East?"
* Fusha: "Ù…Ø§ Ù‡Ùˆ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙÙŠ Ø§Ù„Ø´Ø±Ù‚ Ø§Ù„Ø£ÙˆØ³Ø·ØŸ"
* Dialect: "ÙˆØ´ ØµØ§Ø± Ù…Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨Ø§Ù„Ø®Ù„ÙŠØ¬ØŸ"

ğŸ“Š Outputs:

* Per-layer norms `layer_norm_comparison.png`
* Firepower comparison `firepower_comparison.png`
* Interactive 3D HTML landscape `activation_3d_plot.html`

## ğŸ§¬ NLP Semantic Evaluation (NER, Morphology, Token Fragility)
This module explores:

* ğŸ§  NER recognition of entities (e.g., countries, tech terms)
* ğŸ§± Morphological patterns in dialect Arabic
* ğŸ§© Token fragility: how Arabic phrases are split into unstable subwords

ğŸ¯ Goal: Reveal biases in tokenizer, vocab sparsity, and semantic integrity of LLMs trained mostly on English.

ğŸ“ Files:

* `nlp_eval.py` (entry point)
* `ner_result.json`
* `nlp_spider_plot.png` (NER coverage, language comparison)
* `prompt_ner_fusha.txt`, `prompt_token_fragility.txt`

## ğŸ”­ Visualizations
* ğŸ“ˆ `layer_norm_comparison.png`: Layer-wise processing strength
* ğŸ”¥ `firepower_comparison.png`: Global token intensity
* ğŸ§  `3D_activation_landscape2.png`: Prompt vs. layer vs. norm
* ğŸ•¸ï¸ `nlp_spider_plot.png`: Semantic reach (NER & Morphology)
* ğŸ§© Mermaid diagrams: Flow logic & architecture

## ğŸš€ How to Run
```bash
# Step 1: Prompt Activation
python analyze_prompt_activation.py \
  --model_path ../patched_model_main_bin \
  --prompt "$(cat prompt_fusha.txt)" \
  --output fusha_report.json

# Step 2: NLP Analysis
python nlp_eval.py prompt_ner_fusha.txt ner_result.json

# Step 3: Plotting
python plot_layer_norms_all.py
python plot_firepower.py
python nlp_spider_plot.py
python plot_3d_layernorm.py
